{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette(\"Set2\")\n",
    "sns.set_theme(style=\"whitegrid\", font_scale=2.25)\n",
    "print(sns.color_palette(\"muted\").as_hex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_star(p):\n",
    "    sig = ' '\n",
    "    if p < 0.05:\n",
    "        sig = '*'\n",
    "    if p < 0.01:\n",
    "        sig = '**'\n",
    "    if p < 0.001:\n",
    "        sig = '***'\n",
    "   \n",
    "    return sig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tendency Patterns (BaseGap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basegap_o = pd.read_csv(\"lme_results/offensive_basegap_ci_results2.csv\")\n",
    "basegap_o['label'] = basegap_o['label'].apply(lambda x: x.capitalize())\n",
    "basegap_p = pd.read_csv(\"lme_results/polite_basegap_ci_results2.csv\")\n",
    "basegap_p['label'] = basegap_p['label'].apply(lambda x: x.capitalize())\n",
    "\n",
    "basegap_o_gender = basegap_o[basegap_o['label']=='Woman']\n",
    "basegap_p_gender = basegap_p[basegap_p['label']=='Woman']\n",
    "\n",
    "options = ['Black', 'Asian']\n",
    "basegap_o_ethnicity = basegap_o.loc[basegap_o['label'].isin(options)]\n",
    "basegap_p_ethnicity = basegap_p.loc[basegap_p['label'].isin(options)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(29, 14),\n",
    "                         gridspec_kw={'width_ratios': [1.3, 2], 'height_ratios': [1, 1]})\n",
    "\n",
    "(sns.barplot(data=basegap_o_gender, ax=axes[0, 0],\n",
    "              x='label', y='coef', hue='model',\n",
    "              palette='deep', alpha=0.85)\n",
    ".set(title=\"Offensiveness, Gender\", xlabel=\"\", ylabel=\"Change of Prediction Error\"))\n",
    "\n",
    "(sns.barplot(data=basegap_o_ethnicity, ax=axes[0, 1],\n",
    "              x='label', y='coef', hue='model',\n",
    "              palette='deep', alpha=0.85)\n",
    ".set(title=\"Offensiveness, Ethnicity\", xlabel=\"\", ylabel=\"\"))\n",
    "\n",
    "(sns.barplot(data=basegap_p_gender, ax=axes[1, 0],\n",
    "              x='label', y='coef', hue='model',\n",
    "              palette='deep', alpha=0.85)\n",
    ".set(title=\"Politeness, Gender\", xlabel=\"\", ylabel=\"Change of Prediction Error\"))\n",
    "\n",
    "(sns.barplot(data=basegap_p_ethnicity, ax=axes[1, 1],\n",
    "              x='label', y='coef', hue='model',\n",
    "              palette='deep', alpha=0.85)\n",
    ".set(title=\"Politeness, Ethnicity\", xlabel=\"\", ylabel=\"\"))\n",
    "\n",
    "for ax in axes.flat:\n",
    "    ax.get_legend().remove()\n",
    "    ax.grid(False)\n",
    "    ax.axhline(y=0, color='black', linestyle='dashed', alpha=.5)\n",
    "\n",
    "axes[0,0].annotate(\"reference=Man\", (-0.5,0.002), fontsize=17)\n",
    "axes[1,0].annotate(\"reference=Man\", (-0.5,0.002), fontsize=17)\n",
    "axes[0,1].annotate(\"reference=White\", (-0.5,-0.03), fontsize=17)\n",
    "axes[1,1].annotate(\"reference=White\", (-0.5,-0.03), fontsize=17)\n",
    "\n",
    "handles, labels = axes[0,0].get_legend_handles_labels()\n",
    "handles = handles\n",
    "labels = [\"FLAN-T5\", \"FLAN-UL2\", \"Tulu2-7B\", \"Tulu2-13B\", \"GPT3.5\", \"GPT4\",\n",
    "          \"Llama3.1-8B\", \"Mistral0.3-7B\", \"Qwen2.5-7B\"]\n",
    "fig.legend(handles, labels, loc='upper center', ncol=9)\n",
    "\n",
    "axes[0,0].set_ylim(-0.1, 0.05)\n",
    "axes[1,0].set_ylim(-0.1, 0.05)\n",
    "axes[0,1].set_ylim(-0.15, 0.4)\n",
    "axes[1,1].set_ylim(-0.15, 0.4)\n",
    "        \n",
    "plt.subplots_adjust(hspace=0.3, wspace=0.2)\n",
    "\n",
    "plt.savefig(\"plots/plot_v3_base_gap.pdf\", format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of Adding Identity in Prompt (AddGap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addgap_o = pd.read_csv(\"lme_results/offensive_addgap_ci_results2.csv\")\n",
    "addgap_o['label'] = addgap_o['label'].apply(lambda x: x.capitalize())\n",
    "addgap_p = pd.read_csv(\"lme_results/polite_addgap_ci_results2.csv\")\n",
    "addgap_p['label'] = addgap_p['label'].apply(lambda x: x.capitalize())\n",
    "\n",
    "options = ['Man', 'Woman']\n",
    "addgap_o_gender = addgap_o[addgap_o['label'].isin(options)]\n",
    "addgap_p_gender = addgap_p[addgap_p['label'].isin(options)]\n",
    "\n",
    "options = ['White', 'Black', 'Asian']\n",
    "addgap_o_ethnicity = addgap_o.loc[addgap_o['label'].isin(options)]\n",
    "addgap_p_ethnicity = addgap_p.loc[addgap_p['label'].isin(options)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(29, 13))\n",
    "\n",
    "(sns.pointplot(data=addgap_o_gender, ax=axes[0, 0],\n",
    "              x='label', y='coef', hue='model',\n",
    "              errorbar=(lambda x: (x.min(), x.max())),\n",
    "              palette='deep', linestyles='none', dodge=.4)\n",
    ".set(title=\"Offensiveness, Gender\", xlabel=\"\", ylabel=\"Change of Prediction Error\"))\n",
    "\n",
    "(sns.pointplot(data=addgap_o_ethnicity, ax=axes[0, 1],\n",
    "              x='label', y='coef', hue='model',\n",
    "              errorbar=(lambda x: (x.min(), x.max())),\n",
    "              palette='deep', linestyles='none', dodge=.4)\n",
    ".set(title=\"Offensiveness, Ethnicity\", xlabel=\"\", ylabel=\"\"))\n",
    "\n",
    "(sns.pointplot(data=addgap_p_gender, ax=axes[1, 0],\n",
    "              x='label', y='coef', hue='model',\n",
    "              errorbar=(lambda x: (x.min(), x.max())),\n",
    "              palette='deep', linestyles='none', dodge=.4)\n",
    ".set(title=\"Politeness, Gender\", xlabel=\"\", ylabel=\"Change of Prediction Error\"))\n",
    "\n",
    "(sns.pointplot(data=addgap_p_ethnicity, ax=axes[1, 1],\n",
    "              x='label', y='coef', hue='model',\n",
    "              errorbar=(lambda x: (x.min(), x.max())),\n",
    "              palette='deep', linestyles='none', dodge=.4)\n",
    ".set(title=\"Politeness, Ethnicity\", xlabel=\"\", ylabel=\"\"))\n",
    "\n",
    "for ax in axes.flat:\n",
    "    ax.get_legend().remove()\n",
    "    ax.grid(False)\n",
    "    ax.axhline(y=0, color='black', linestyle='dashed', alpha=.5)\n",
    "\n",
    "handles, labels = axes[0,0].get_legend_handles_labels()\n",
    "handles = handles\n",
    "labels = [\"FLAN-T5\", \"FLAN-UL2\", \"Tulu2-7B\", \"Tulu2-13B\", \"GPT3.5\", \"GPT4\",\n",
    "          \"Llama3.1-8B\", \"Mistral0.3-7B\", \"Qwen2.5-7B\"]\n",
    "fig.legend(handles, labels, loc='upper center', ncol=9)\n",
    "\n",
    "\n",
    "plot_dfs = [addgap_o_gender, addgap_o_ethnicity, addgap_p_gender, addgap_o_ethnicity]\n",
    "\n",
    "for i in range(0, len(axes.flat)):\n",
    "    plot_df = plot_dfs[i]\n",
    "    plot_df = plot_df.drop_duplicates(subset=['model', 'label'], keep='first')\n",
    "    pvalues = plot_df['p'].to_list()\n",
    "    x_values = np.ma.concatenate([[path.get_offsets()[:,0] for path in axes.flat[i].collections][0],\n",
    "                                [path.get_offsets()[:,0] for path in axes.flat[i].collections][1],\n",
    "                                [path.get_offsets()[:,0] for path in axes.flat[i].collections][2],\n",
    "                                [path.get_offsets()[:,0] for path in axes.flat[i].collections][3],\n",
    "                                [path.get_offsets()[:,0] for path in axes.flat[i].collections][4],\n",
    "                                [path.get_offsets()[:,0] for path in axes.flat[i].collections][5],\n",
    "                                [path.get_offsets()[:,0] for path in axes.flat[i].collections][6],\n",
    "                                [path.get_offsets()[:,0] for path in axes.flat[i].collections][7],\n",
    "                                [path.get_offsets()[:,0] for path in axes.flat[i].collections][8]]).tolist()\n",
    "    y_values = np.ma.concatenate([[path.get_offsets()[:,1] for path in axes.flat[i].collections][0],\n",
    "                                [path.get_offsets()[:,1] for path in axes.flat[i].collections][1],\n",
    "                                [path.get_offsets()[:,1] for path in axes.flat[i].collections][2],\n",
    "                                [path.get_offsets()[:,1] for path in axes.flat[i].collections][3],\n",
    "                                [path.get_offsets()[:,1] for path in axes.flat[i].collections][4],\n",
    "                                [path.get_offsets()[:,1] for path in axes.flat[i].collections][5],\n",
    "                                [path.get_offsets()[:,1] for path in axes.flat[i].collections][6],\n",
    "                                [path.get_offsets()[:,1] for path in axes.flat[i].collections][7],\n",
    "                                [path.get_offsets()[:,1] for path in axes.flat[i].collections][8]]).tolist()\n",
    "    sigs = [add_star(p) for p in pvalues]\n",
    "\n",
    "    for j, sig in enumerate(sigs):\n",
    "        axes.flat[i].annotate(sig, (x_values[j]+0.005, y_values[j]+0.005),\n",
    "                              fontsize=15, rotation=90)\n",
    "        \n",
    "plt.subplots_adjust(hspace=0.3)\n",
    "\n",
    "plt.savefig(\"plots/plot_v3_add_gap.pdf\", format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions of Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_o = pd.read_table(\"../LLM_pred/offensive_results_w.tsv\")\n",
    "results_p = pd.read_table(\"../LLM_pred/polite_results_w.tsv\")\n",
    "\n",
    "label_o = pd.melt(results_o.loc[:, 'label':'asian_score'], var_name='group', value_name='score')\n",
    "label_o['dimension'] = 'Offensiveness'\n",
    "label_p = pd.melt(results_p.loc[:, 'label':'asian_score'], var_name='group', value_name='score')\n",
    "label_p['dimension'] = 'Politeness'\n",
    "labels  = pd.concat([label_o, label_p], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = sns.catplot(data=labels, x='group', y='score', col='dimension', kind='violin',\n",
    "                 height=3, aspect=1.7, sharey=False)\n",
    "p1.set_axis_labels(\"\", \"Scores\")\n",
    "p1.set_xticklabels([\"US Population\", \"Man\", \"Woman\", \"White\", \"Black\", \"Asian\"])\n",
    "p1.set_titles(\"{col_name}\")\n",
    "p1.savefig(\"plots/plot_v1_score_dist.pdf\", format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robustness Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_robust = pd.read_csv(\"../LLM_pred/corr_robust_l.csv\")\n",
    "corr_robust_o = corr_robust[corr_robust['dimension']=='offensiveness']\n",
    "corr_robust_p = corr_robust[corr_robust['dimension']=='politeness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(21, 5.5))\n",
    "\n",
    "col1 = ['#4878d0', '#ee854a', '#6acc64', '#dc7ec0', '#797979', '#d5bb67', '#82c6e2']\n",
    "\n",
    "(sns.barplot(data=corr_robust_o,\n",
    "            x='model', y='corr', hue='prompt',\n",
    "            palette=col1, ax=axes[0])\n",
    ".set(title=\"Offensiveness\", xlabel=\"\", ylabel=\"Correlation Coefficient\"))\n",
    "\n",
    "(sns.barplot(data=corr_robust_p,\n",
    "            x='model', y='corr', hue='prompt',\n",
    "            palette=col1, ax=axes[1])\n",
    ".set(title=\"Politeness\", xlabel=\"\", ylabel=\"Correlation Coefficient\"))\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xticklabels(labels=[\"FLAN-T5\", \"FLAN-UL2\", \"Tulu2-7B\", \"Tulu2-13B\"])\n",
    "    ax.get_legend().remove()\n",
    "\n",
    "handles1, labels1 = axes[0].get_legend_handles_labels()\n",
    "labels = ['Prompt 1', 'Prompt 2', 'Prompt 3']\n",
    "fig.legend(handles1, labels, loc='upper center', ncol=3)\n",
    "\n",
    "plt.savefig(\"../results/plot_v1_robust.pdf\", format='pdf')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
