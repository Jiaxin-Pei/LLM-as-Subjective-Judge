{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offensive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "offensive = pd.read_table(\"offensive_results_w.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_error_base_flant5xxl = -(offensive.loc[:, 'label':'asian_score']).sub(offensive['flant5_xxl_base'], axis=0)\n",
    "o_error_base_flant5xxl['model'] = 'flan_t5_xxl'\n",
    "o_error_base_flan_ul2 = -(offensive.loc[:, 'label':'asian_score']).sub(offensive['flan_ul2_base'], axis=0)\n",
    "o_error_base_flan_ul2['model'] = 'flan_ul2'\n",
    "o_error_base_tulu2_7b = -(offensive.loc[:, 'label':'asian_score']).sub(offensive['tulu2_7b_base'], axis=0)\n",
    "o_error_base_tulu2_7b['model'] = 'tulu2_7b'\n",
    "o_error_base_tulu2_13b = -(offensive.loc[:, 'label':'asian_score']).sub(offensive['tulu2_13b_base'], axis=0)\n",
    "o_error_base_tulu2_13b['model'] = 'tulu2_13b'\n",
    "o_error_base_gpt35 = -(offensive.loc[:, 'label':'asian_score']).sub(offensive['gpt35_base'], axis=0)\n",
    "o_error_base_gpt35['model'] = 'gpt35'\n",
    "o_error_base_gpt4 = -(offensive.loc[:, 'label':'asian_score']).sub(offensive['gpt4_base'], axis=0)\n",
    "o_error_base_gpt4['model'] = 'gpt4'\n",
    "\n",
    "o_error_base = (pd.concat([o_error_base_flant5xxl, o_error_base_flan_ul2, o_error_base_tulu2_7b, o_error_base_tulu2_13b,\n",
    "                          o_error_base_gpt35, o_error_base_gpt4],\n",
    "                          ignore_index=True)\n",
    "                .rename(columns={'label':'overall_score'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_error_identity_flant5xxl = -(offensive.loc[:, 'label':'asian_score']-(offensive.loc[:,'flant5_xxl_base':'flant5_xxl_asian'].values))\n",
    "o_error_identity_flant5xxl['model'] = 'flan_t5_xxl'\n",
    "o_error_identity_flan_ul2 = -(offensive.loc[:, 'label':'asian_score']-(offensive.loc[:, 'flan_ul2_base':'flan_ul2_asian'].values))\n",
    "o_error_identity_flan_ul2['model'] = 'flan_ul2'\n",
    "o_error_identity_tulu2_7b = -(offensive.loc[:, 'label':'asian_score']-(offensive.loc[:, 'tulu2_7b_base':'tulu2_7b_asian'].values))\n",
    "o_error_identity_tulu2_7b['model'] = 'tulu2_7b'\n",
    "o_error_identity_tulu2_13b = -(offensive.loc[:, 'label':'asian_score']-(offensive.loc[:, 'tulu2_13b_base':'tulu2_13b_asian'].values))\n",
    "o_error_identity_tulu2_13b['model'] = 'tulu2_13b'\n",
    "o_error_identity_gpt35 = -(offensive.loc[:, 'label':'asian_score']-(offensive.loc[:, 'gpt35_base':'gpt35_asian'].values))\n",
    "o_error_identity_gpt35['model'] = 'gpt35'\n",
    "o_error_identity_gpt4 = -(offensive.loc[:, 'label':'asian_score']-(offensive.loc[:, 'gpt4_base':'gpt4_asian'].values))\n",
    "o_error_identity_gpt4['model'] = 'gpt4'\n",
    "\n",
    "o_error_identity = (pd.concat([o_error_identity_flant5xxl, o_error_identity_flan_ul2, o_error_identity_tulu2_7b, \n",
    "                               o_error_identity_tulu2_13b, o_error_identity_gpt35, o_error_identity_gpt4],\n",
    "                               ignore_index=True)\n",
    "                .rename(columns={'label':'overall_score'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional Difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base\n",
    "\n",
    "base predictions vs. identity labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">overall_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">man_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">woman_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">white_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">black_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">asian_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>flan_t5_xxl</th>\n",
       "      <td>0.376</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.376</td>\n",
       "      <td>1.033</td>\n",
       "      <td>0.363</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.190</td>\n",
       "      <td>1.343</td>\n",
       "      <td>0.351</td>\n",
       "      <td>1.340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flan_ul2</th>\n",
       "      <td>1.064</td>\n",
       "      <td>1.166</td>\n",
       "      <td>1.064</td>\n",
       "      <td>1.256</td>\n",
       "      <td>1.045</td>\n",
       "      <td>1.238</td>\n",
       "      <td>1.079</td>\n",
       "      <td>1.186</td>\n",
       "      <td>0.882</td>\n",
       "      <td>1.534</td>\n",
       "      <td>1.017</td>\n",
       "      <td>1.458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt35</th>\n",
       "      <td>0.438</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.227</td>\n",
       "      <td>1.196</td>\n",
       "      <td>0.425</td>\n",
       "      <td>1.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4</th>\n",
       "      <td>0.217</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.216</td>\n",
       "      <td>1.089</td>\n",
       "      <td>0.199</td>\n",
       "      <td>1.052</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.012</td>\n",
       "      <td>1.395</td>\n",
       "      <td>0.202</td>\n",
       "      <td>1.388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tulu2_13b</th>\n",
       "      <td>1.372</td>\n",
       "      <td>0.719</td>\n",
       "      <td>1.369</td>\n",
       "      <td>0.835</td>\n",
       "      <td>1.359</td>\n",
       "      <td>0.856</td>\n",
       "      <td>1.387</td>\n",
       "      <td>0.747</td>\n",
       "      <td>1.173</td>\n",
       "      <td>1.236</td>\n",
       "      <td>1.353</td>\n",
       "      <td>1.157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tulu2_7b</th>\n",
       "      <td>1.910</td>\n",
       "      <td>0.966</td>\n",
       "      <td>1.916</td>\n",
       "      <td>1.071</td>\n",
       "      <td>1.898</td>\n",
       "      <td>1.063</td>\n",
       "      <td>1.927</td>\n",
       "      <td>0.979</td>\n",
       "      <td>1.694</td>\n",
       "      <td>1.422</td>\n",
       "      <td>1.895</td>\n",
       "      <td>1.357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            overall_score        man_score        woman_score         \\\n",
       "                     mean    std      mean    std        mean    std   \n",
       "model                                                                  \n",
       "flan_t5_xxl         0.376  0.924     0.376  1.033       0.363  1.018   \n",
       "flan_ul2            1.064  1.166     1.064  1.256       1.045  1.238   \n",
       "gpt35               0.438  0.647     0.435  0.784       0.425  0.788   \n",
       "gpt4                0.217  0.980     0.216  1.089       0.199  1.052   \n",
       "tulu2_13b           1.372  0.719     1.369  0.835       1.359  0.856   \n",
       "tulu2_7b            1.910  0.966     1.916  1.071       1.898  1.063   \n",
       "\n",
       "            white_score        black_score        asian_score         \n",
       "                   mean    std        mean    std        mean    std  \n",
       "model                                                                 \n",
       "flan_t5_xxl       0.391  0.954       0.190  1.343       0.351  1.340  \n",
       "flan_ul2          1.079  1.186       0.882  1.534       1.017  1.458  \n",
       "gpt35             0.454  0.678       0.227  1.196       0.425  1.097  \n",
       "gpt4              0.233  0.989       0.012  1.395       0.202  1.388  \n",
       "tulu2_13b         1.387  0.747       1.173  1.236       1.353  1.157  \n",
       "tulu2_7b          1.927  0.979       1.694  1.422       1.895  1.357  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o_error_base.groupby(['model']).agg([np.mean, np.std]).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idendity\n",
    "\n",
    "identity predictions vs. identity labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">overall_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">man_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">woman_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">white_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">black_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">asian_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>flan_t5_xxl</th>\n",
       "      <td>0.376</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.425</td>\n",
       "      <td>1.098</td>\n",
       "      <td>0.453</td>\n",
       "      <td>1.096</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.107</td>\n",
       "      <td>1.410</td>\n",
       "      <td>0.316</td>\n",
       "      <td>1.383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flan_ul2</th>\n",
       "      <td>1.064</td>\n",
       "      <td>1.166</td>\n",
       "      <td>1.146</td>\n",
       "      <td>1.247</td>\n",
       "      <td>1.090</td>\n",
       "      <td>1.296</td>\n",
       "      <td>0.837</td>\n",
       "      <td>1.287</td>\n",
       "      <td>0.272</td>\n",
       "      <td>1.692</td>\n",
       "      <td>0.090</td>\n",
       "      <td>1.537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt35</th>\n",
       "      <td>0.438</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.726</td>\n",
       "      <td>-0.230</td>\n",
       "      <td>1.163</td>\n",
       "      <td>0.070</td>\n",
       "      <td>1.092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4</th>\n",
       "      <td>0.217</td>\n",
       "      <td>0.980</td>\n",
       "      <td>-0.326</td>\n",
       "      <td>0.944</td>\n",
       "      <td>-0.188</td>\n",
       "      <td>1.024</td>\n",
       "      <td>-0.578</td>\n",
       "      <td>0.785</td>\n",
       "      <td>-0.849</td>\n",
       "      <td>1.303</td>\n",
       "      <td>-0.666</td>\n",
       "      <td>1.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tulu2_13b</th>\n",
       "      <td>1.372</td>\n",
       "      <td>0.719</td>\n",
       "      <td>1.151</td>\n",
       "      <td>0.845</td>\n",
       "      <td>1.031</td>\n",
       "      <td>0.876</td>\n",
       "      <td>1.217</td>\n",
       "      <td>0.734</td>\n",
       "      <td>1.074</td>\n",
       "      <td>1.318</td>\n",
       "      <td>1.093</td>\n",
       "      <td>1.192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tulu2_7b</th>\n",
       "      <td>1.910</td>\n",
       "      <td>0.966</td>\n",
       "      <td>1.864</td>\n",
       "      <td>0.979</td>\n",
       "      <td>1.856</td>\n",
       "      <td>0.970</td>\n",
       "      <td>1.754</td>\n",
       "      <td>0.901</td>\n",
       "      <td>1.597</td>\n",
       "      <td>1.335</td>\n",
       "      <td>1.826</td>\n",
       "      <td>1.225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            overall_score        man_score        woman_score         \\\n",
       "                     mean    std      mean    std        mean    std   \n",
       "model                                                                  \n",
       "flan_t5_xxl         0.376  0.924     0.425  1.098       0.453  1.096   \n",
       "flan_ul2            1.064  1.166     1.146  1.247       1.090  1.296   \n",
       "gpt35               0.438  0.647     0.275  0.798       0.266  0.811   \n",
       "gpt4                0.217  0.980    -0.326  0.944      -0.188  1.024   \n",
       "tulu2_13b           1.372  0.719     1.151  0.845       1.031  0.876   \n",
       "tulu2_7b            1.910  0.966     1.864  0.979       1.856  0.970   \n",
       "\n",
       "            white_score        black_score        asian_score         \n",
       "                   mean    std        mean    std        mean    std  \n",
       "model                                                                 \n",
       "flan_t5_xxl       0.105  0.944       0.107  1.410       0.316  1.383  \n",
       "flan_ul2          0.837  1.287       0.272  1.692       0.090  1.537  \n",
       "gpt35             0.019  0.726      -0.230  1.163       0.070  1.092  \n",
       "gpt4             -0.578  0.785      -0.849  1.303      -0.666  1.187  \n",
       "tulu2_13b         1.217  0.734       1.074  1.318       1.093  1.192  \n",
       "tulu2_7b          1.754  0.901       1.597  1.335       1.826  1.225  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o_error_identity.groupby(['model']).agg([np.mean, np.std]).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base, Distance\n",
    "\n",
    "an indirect statistical test to justify our findings in Fig 2.\n",
    "\n",
    "(We conduct post hoc t-tests with Bonferoni correction to ensure that there are between-group differences in the distances between base predictions and identity labels. In our main findings, we use the gaps in correlation coefficients to illustrate which group the base predictions are closer to.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = o_error_base['model'].unique()\n",
    "results = {'model':[], 'pair':[], 't_stat':[], 'p_value':[]}\n",
    "\n",
    "for i in models:\n",
    "    df = o_error_base[o_error_base['model']==i]\n",
    "    g = stats.ttest_rel(df['man_score'], df['woman_score'], nan_policy=\"omit\")\n",
    "    e1 = stats.ttest_rel(df['white_score'], df['black_score'], nan_policy=\"omit\")\n",
    "    e2 = stats.ttest_rel(df['white_score'], df['asian_score'], nan_policy=\"omit\")\n",
    "    e3 = stats.ttest_rel(df['black_score'], df['asian_score'], nan_policy=\"omit\")\n",
    "    results['model'].extend([i,i,i,i])\n",
    "    results['pair'].extend(['man_woman', 'white_black', 'white_asian', 'black_asian'])\n",
    "    results['t_stat'].extend([g[0], e1[0], e2[0], e3[0]])\n",
    "    results['p_value'].extend([g[1], e1[1], e2[1], e3[1]])\n",
    "\n",
    "o_results_base = pd.DataFrame.from_dict(results, orient=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">t_stat</th>\n",
       "      <th colspan=\"4\" halign=\"left\">p_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pair</th>\n",
       "      <th>black_asian</th>\n",
       "      <th>man_woman</th>\n",
       "      <th>white_asian</th>\n",
       "      <th>white_black</th>\n",
       "      <th>black_asian</th>\n",
       "      <th>man_woman</th>\n",
       "      <th>white_asian</th>\n",
       "      <th>white_black</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>flan_t5_xxl</th>\n",
       "      <td>-1.136</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.973</td>\n",
       "      <td>6.142</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flan_ul2</th>\n",
       "      <td>-1.136</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.973</td>\n",
       "      <td>6.142</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt35</th>\n",
       "      <td>-1.176</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.911</td>\n",
       "      <td>6.139</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4</th>\n",
       "      <td>-1.136</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.973</td>\n",
       "      <td>6.142</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tulu2_13b</th>\n",
       "      <td>-0.809</td>\n",
       "      <td>0.649</td>\n",
       "      <td>1.039</td>\n",
       "      <td>5.964</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.516</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tulu2_7b</th>\n",
       "      <td>-1.150</td>\n",
       "      <td>0.790</td>\n",
       "      <td>1.155</td>\n",
       "      <td>5.673</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 t_stat                                       p_value  \\\n",
       "pair        black_asian man_woman white_asian white_black black_asian   \n",
       "model                                                                   \n",
       "flan_t5_xxl      -1.136     0.692       0.973       6.142       0.256   \n",
       "flan_ul2         -1.136     0.692       0.973       6.142       0.256   \n",
       "gpt35            -1.176     0.607       0.911       6.139       0.240   \n",
       "gpt4             -1.136     0.692       0.973       6.142       0.256   \n",
       "tulu2_13b        -0.809     0.649       1.039       5.964       0.419   \n",
       "tulu2_7b         -1.150     0.790       1.155       5.673       0.251   \n",
       "\n",
       "                                               \n",
       "pair        man_woman white_asian white_black  \n",
       "model                                          \n",
       "flan_t5_xxl     0.489       0.331         0.0  \n",
       "flan_ul2        0.489       0.331         0.0  \n",
       "gpt35           0.544       0.363         0.0  \n",
       "gpt4            0.489       0.331         0.0  \n",
       "tulu2_13b       0.516       0.299         0.0  \n",
       "tulu2_7b        0.430       0.248         0.0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o_results_base.pivot(index='model', columns='pair', values=['t_stat', 'p_value']).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distance\n",
    "\n",
    "show that adding identity tokens has influence on the alignment of models' predictions to subgroup labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = o_error_identity['model'].unique()\n",
    "results = {'model':[], 'identity':[], 't_stat':[], 'p_value':[]}\n",
    "\n",
    "for i in models:\n",
    "    df_base = o_error_base[o_error_base['model']==i]\n",
    "    df_identity = o_error_identity[o_error_identity['model']==i]\n",
    "    man = stats.ttest_rel(df_base['man_score'], df_identity['man_score'], nan_policy=\"omit\")\n",
    "    woman = stats.ttest_rel(df_base['woman_score'], df_identity['woman_score'], nan_policy=\"omit\")\n",
    "    white = stats.ttest_rel(df_base['white_score'], df_identity['white_score'], nan_policy=\"omit\")\n",
    "    black = stats.ttest_rel(df_base['black_score'], df_identity['black_score'], nan_policy=\"omit\")\n",
    "    asian = stats.ttest_rel(df_base['asian_score'], df_identity['asian_score'], nan_policy=\"omit\")\n",
    "    results['model'].extend([i,i,i,i,i])\n",
    "    results['identity'].extend(['man', 'woman', 'white', 'black', 'asian'])\n",
    "    results['t_stat'].extend([man[0], woman[0], white[0], black[0], asian[0]])\n",
    "    results['p_value'].extend([man[1], woman[1], white[1], black[1], asian[1]])\n",
    "\n",
    "o_results_identity = pd.DataFrame.from_dict(results, orient=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">t_stat</th>\n",
       "      <th colspan=\"5\" halign=\"left\">p_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>identity</th>\n",
       "      <th>asian</th>\n",
       "      <th>black</th>\n",
       "      <th>man</th>\n",
       "      <th>white</th>\n",
       "      <th>woman</th>\n",
       "      <th>asian</th>\n",
       "      <th>black</th>\n",
       "      <th>man</th>\n",
       "      <th>white</th>\n",
       "      <th>woman</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>flan_t5_xxl</th>\n",
       "      <td>1.904</td>\n",
       "      <td>3.710</td>\n",
       "      <td>-4.409</td>\n",
       "      <td>17.476</td>\n",
       "      <td>-7.420</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flan_ul2</th>\n",
       "      <td>19.024</td>\n",
       "      <td>15.933</td>\n",
       "      <td>-5.200</td>\n",
       "      <td>10.904</td>\n",
       "      <td>-2.656</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt35</th>\n",
       "      <td>10.536</td>\n",
       "      <td>12.181</td>\n",
       "      <td>13.467</td>\n",
       "      <td>25.199</td>\n",
       "      <td>9.783</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4</th>\n",
       "      <td>18.470</td>\n",
       "      <td>22.211</td>\n",
       "      <td>25.987</td>\n",
       "      <td>28.762</td>\n",
       "      <td>18.038</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tulu2_13b</th>\n",
       "      <td>9.260</td>\n",
       "      <td>3.231</td>\n",
       "      <td>16.159</td>\n",
       "      <td>12.226</td>\n",
       "      <td>21.584</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tulu2_7b</th>\n",
       "      <td>1.948</td>\n",
       "      <td>2.885</td>\n",
       "      <td>2.626</td>\n",
       "      <td>8.273</td>\n",
       "      <td>1.750</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             t_stat                                 p_value                \\\n",
       "identity      asian   black     man   white   woman   asian  black    man   \n",
       "model                                                                       \n",
       "flan_t5_xxl   1.904   3.710  -4.409  17.476  -7.420   0.057  0.000  0.000   \n",
       "flan_ul2     19.024  15.933  -5.200  10.904  -2.656   0.000  0.000  0.000   \n",
       "gpt35        10.536  12.181  13.467  25.199   9.783   0.000  0.000  0.000   \n",
       "gpt4         18.470  22.211  25.987  28.762  18.038   0.000  0.000  0.000   \n",
       "tulu2_13b     9.260   3.231  16.159  12.226  21.584   0.000  0.001  0.000   \n",
       "tulu2_7b      1.948   2.885   2.626   8.273   1.750   0.052  0.004  0.009   \n",
       "\n",
       "                          \n",
       "identity    white  woman  \n",
       "model                     \n",
       "flan_t5_xxl   0.0  0.000  \n",
       "flan_ul2      0.0  0.008  \n",
       "gpt35         0.0  0.000  \n",
       "gpt4          0.0  0.000  \n",
       "tulu2_13b     0.0  0.000  \n",
       "tulu2_7b      0.0  0.080  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o_results_identity.pivot(index='model', columns='identity', values=['t_stat', 'p_value']).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction\n",
    "\n",
    "show that there is significant difference of models' behavior w/o identity tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_pred_error = (offensive.loc[:, 'flant5_xxl_base':'gpt4_asian'].reset_index()\n",
    "                .melt(id_vars='index', value_name='pred', var_name='var'))\n",
    "o_pred_error['model'] = o_pred_error['var'].apply(lambda x: re.split(r'_[a-z]+$', x)[0])\n",
    "o_pred_error['identity'] = o_pred_error['var'].apply(lambda x: re.findall(r'[a-z]+$', x)[0])\n",
    "del o_pred_error['var']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = o_pred_error['model'].unique()\n",
    "identities = o_pred_error['identity'].unique()\n",
    "results = {'model':[], 'identity':[], 't_stat':[], 'p_value':[]}\n",
    "\n",
    "for i in models:\n",
    "    df = o_pred_error[o_pred_error['model']==i]\n",
    "    df_base = df[df['identity']=='base']\n",
    "    for j in identities:\n",
    "        if j == \"base\":\n",
    "            continue\n",
    "        df_identity = df[df['identity']==j]\n",
    "        ttest = stats.ttest_rel(df_base['pred'], df_identity['pred'], nan_policy='omit')\n",
    "        results['model'].append(i)\n",
    "        results['identity'].append(j)\n",
    "        results['t_stat'].append(ttest[0])\n",
    "        results['p_value'].append(ttest[1])\n",
    "\n",
    "o_results_pred = pd.DataFrame.from_dict(results, orient=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">t_stat</th>\n",
       "      <th colspan=\"5\" halign=\"left\">p_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>identity</th>\n",
       "      <th>asian</th>\n",
       "      <th>black</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>white</th>\n",
       "      <th>asian</th>\n",
       "      <th>black</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>white</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>flan_ul2</th>\n",
       "      <td>29.009</td>\n",
       "      <td>18.731</td>\n",
       "      <td>-2.599</td>\n",
       "      <td>-5.316</td>\n",
       "      <td>10.904</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flant5_xxl</th>\n",
       "      <td>0.923</td>\n",
       "      <td>4.469</td>\n",
       "      <td>-7.420</td>\n",
       "      <td>-4.569</td>\n",
       "      <td>17.476</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt35</th>\n",
       "      <td>14.713</td>\n",
       "      <td>14.879</td>\n",
       "      <td>9.839</td>\n",
       "      <td>13.710</td>\n",
       "      <td>25.199</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4</th>\n",
       "      <td>26.593</td>\n",
       "      <td>27.069</td>\n",
       "      <td>18.109</td>\n",
       "      <td>26.157</td>\n",
       "      <td>28.762</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tulu2_13b</th>\n",
       "      <td>12.461</td>\n",
       "      <td>3.293</td>\n",
       "      <td>21.661</td>\n",
       "      <td>16.262</td>\n",
       "      <td>12.226</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tulu2_7b</th>\n",
       "      <td>2.429</td>\n",
       "      <td>3.784</td>\n",
       "      <td>1.791</td>\n",
       "      <td>2.518</td>\n",
       "      <td>8.273</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            t_stat                                 p_value                \\\n",
       "identity     asian   black  female    male   white   asian  black female   \n",
       "model                                                                      \n",
       "flan_ul2    29.009  18.731  -2.599  -5.316  10.904   0.000  0.000  0.009   \n",
       "flant5_xxl   0.923   4.469  -7.420  -4.569  17.476   0.356  0.000  0.000   \n",
       "gpt35       14.713  14.879   9.839  13.710  25.199   0.000  0.000  0.000   \n",
       "gpt4        26.593  27.069  18.109  26.157  28.762   0.000  0.000  0.000   \n",
       "tulu2_13b   12.461   3.293  21.661  16.262  12.226   0.000  0.001  0.000   \n",
       "tulu2_7b     2.429   3.784   1.791   2.518   8.273   0.015  0.000  0.074   \n",
       "\n",
       "                         \n",
       "identity     male white  \n",
       "model                    \n",
       "flan_ul2    0.000   0.0  \n",
       "flant5_xxl  0.000   0.0  \n",
       "gpt35       0.000   0.0  \n",
       "gpt4        0.000   0.0  \n",
       "tulu2_13b   0.000   0.0  \n",
       "tulu2_7b    0.012   0.0  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o_results_pred.pivot(index='model', columns='identity', values=['t_stat', 'p_value']).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Politeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "polite = pd.read_table(\"polite_results_w.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_error_base_flant5xxl = -(polite.loc[:, 'label':'asian_score']).sub(polite['flant5_xxl_base'], axis=0)\n",
    "p_error_base_flant5xxl['model'] = 'flan_t5_xxl'\n",
    "p_error_base_flan_ul2 = -(polite.loc[:, 'label':'asian_score']).sub(polite['flan_ul2_base'], axis=0)\n",
    "p_error_base_flan_ul2['model'] = 'flan_ul2'\n",
    "p_error_base_tulu2_7b = -(polite.loc[:, 'label':'asian_score']).sub(polite['tulu2_7b_base'], axis=0)\n",
    "p_error_base_tulu2_7b['model'] = 'tulu2_7b'\n",
    "p_error_base_tulu2_13b = -(polite.loc[:, 'label':'asian_score']).sub(polite['tulu2_13b_base'], axis=0)\n",
    "p_error_base_tulu2_13b['model'] = 'tulu2_13b'\n",
    "p_error_base_gpt35 = -(polite.loc[:, 'label':'asian_score']).sub(polite['gpt35_base'], axis=0)\n",
    "p_error_base_gpt35['model'] = 'gpt35'\n",
    "p_error_base_gpt4 = -(polite.loc[:, 'label':'asian_score']).sub(polite['gpt4_base'], axis=0)\n",
    "p_error_base_gpt4['model'] = 'gpt4'\n",
    "\n",
    "p_error_base = (pd.concat([p_error_base_flant5xxl, p_error_base_flan_ul2, p_error_base_tulu2_7b, p_error_base_tulu2_13b,\n",
    "                          p_error_base_gpt35, p_error_base_gpt4],\n",
    "                          ignore_index=True)\n",
    "                .rename(columns={'label':'overall_score'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_error_identity_flant5xxl = -(polite.loc[:, 'label':'asian_score']-(polite.loc[:,'flant5_xxl_base':'flant5_xxl_asian'].values))\n",
    "p_error_identity_flant5xxl['model'] = 'flan_t5_xxl'\n",
    "p_error_identity_flan_ul2 = -(polite.loc[:, 'label':'asian_score']-(polite.loc[:, 'flan_ul2_base':'flan_ul2_asian'].values))\n",
    "p_error_identity_flan_ul2['model'] = 'flan_ul2'\n",
    "p_error_identity_tulu2_7b = -(polite.loc[:, 'label':'asian_score']-(polite.loc[:, 'tulu2_7b_base':'tulu2_7b_asian'].values))\n",
    "p_error_identity_tulu2_7b['model'] = 'tulu2_7b'\n",
    "p_error_identity_tulu2_13b = -(polite.loc[:, 'label':'asian_score']-(polite.loc[:, 'tulu2_13b_base':'tulu2_13b_asian'].values))\n",
    "p_error_identity_tulu2_13b['model'] = 'tulu2_13b'\n",
    "p_error_identity_gpt35 = -(polite.loc[:, 'label':'asian_score']-(polite.loc[:, 'gpt35_base':'gpt35_asian'].values))\n",
    "p_error_identity_gpt35['model'] = 'gpt35'\n",
    "p_error_identity_gpt4 = -(polite.loc[:, 'label':'asian_score']-(polite.loc[:, 'gpt4_base':'gpt4_asian'].values))\n",
    "p_error_identity_gpt4['model'] = 'gpt4'\n",
    "\n",
    "p_error_identity = (pd.concat([p_error_identity_flant5xxl, p_error_identity_flan_ul2, p_error_identity_tulu2_7b,\n",
    "                               p_error_identity_tulu2_13b, p_error_identity_gpt35, p_error_identity_gpt4],\n",
    "                               ignore_index=True)\n",
    "                .rename(columns={'label':'overall_score'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional Difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base\n",
    "\n",
    "base predictions vs. identity labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">overall_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">man_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">woman_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">white_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">black_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">asian_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>flan_t5_xxl</th>\n",
       "      <td>0.210</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.196</td>\n",
       "      <td>1.030</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.116</td>\n",
       "      <td>1.232</td>\n",
       "      <td>0.309</td>\n",
       "      <td>1.195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flan_ul2</th>\n",
       "      <td>0.597</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.585</td>\n",
       "      <td>1.021</td>\n",
       "      <td>0.594</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.487</td>\n",
       "      <td>1.237</td>\n",
       "      <td>0.705</td>\n",
       "      <td>1.215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt35</th>\n",
       "      <td>-0.041</td>\n",
       "      <td>0.629</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>0.784</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>0.767</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>0.673</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>1.050</td>\n",
       "      <td>0.058</td>\n",
       "      <td>1.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4</th>\n",
       "      <td>0.605</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.495</td>\n",
       "      <td>1.114</td>\n",
       "      <td>0.703</td>\n",
       "      <td>1.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tulu2_13b</th>\n",
       "      <td>0.048</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.801</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>1.145</td>\n",
       "      <td>0.160</td>\n",
       "      <td>1.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tulu2_7b</th>\n",
       "      <td>0.024</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.844</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>1.161</td>\n",
       "      <td>0.137</td>\n",
       "      <td>1.160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            overall_score        man_score        woman_score         \\\n",
       "                     mean    std      mean    std        mean    std   \n",
       "model                                                                  \n",
       "flan_t5_xxl         0.210  0.891     0.196  1.030       0.205  0.971   \n",
       "flan_ul2            0.597  0.901     0.585  1.021       0.594  1.001   \n",
       "gpt35              -0.041  0.629    -0.057  0.784      -0.045  0.767   \n",
       "gpt4                0.605  0.719     0.590  0.889       0.601  0.816   \n",
       "tulu2_13b           0.048  0.764     0.032  0.908       0.046  0.882   \n",
       "tulu2_7b            0.024  0.816     0.012  0.944       0.022  0.935   \n",
       "\n",
       "            white_score        black_score        asian_score         \n",
       "                   mean    std        mean    std        mean    std  \n",
       "model                                                                 \n",
       "flan_t5_xxl       0.211  0.917       0.116  1.232       0.309  1.195  \n",
       "flan_ul2          0.598  0.929       0.487  1.237       0.705  1.215  \n",
       "gpt35            -0.040  0.673      -0.147  1.050       0.058  1.004  \n",
       "gpt4              0.606  0.757       0.495  1.114       0.703  1.061  \n",
       "tulu2_13b         0.048  0.801      -0.039  1.145       0.160  1.081  \n",
       "tulu2_7b          0.025  0.844      -0.068  1.161       0.137  1.160  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_error_base.groupby(['model']).agg([np.mean, np.std]).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idendity\n",
    "\n",
    "identity predictions vs. identity labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">overall_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">man_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">woman_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">white_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">black_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">asian_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>flan_t5_xxl</th>\n",
       "      <td>0.210</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.204</td>\n",
       "      <td>1.062</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.186</td>\n",
       "      <td>1.269</td>\n",
       "      <td>0.215</td>\n",
       "      <td>1.195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flan_ul2</th>\n",
       "      <td>0.597</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.669</td>\n",
       "      <td>1.003</td>\n",
       "      <td>0.570</td>\n",
       "      <td>1.011</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.379</td>\n",
       "      <td>1.229</td>\n",
       "      <td>0.505</td>\n",
       "      <td>1.211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt35</th>\n",
       "      <td>-0.041</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.776</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.691</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>1.072</td>\n",
       "      <td>0.024</td>\n",
       "      <td>1.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4</th>\n",
       "      <td>0.605</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.792</td>\n",
       "      <td>1.123</td>\n",
       "      <td>0.538</td>\n",
       "      <td>1.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tulu2_13b</th>\n",
       "      <td>0.048</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.893</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.176</td>\n",
       "      <td>1.151</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>1.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tulu2_7b</th>\n",
       "      <td>0.024</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.911</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.781</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>1.095</td>\n",
       "      <td>0.243</td>\n",
       "      <td>1.123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            overall_score        man_score        woman_score         \\\n",
       "                     mean    std      mean    std        mean    std   \n",
       "model                                                                  \n",
       "flan_t5_xxl         0.210  0.891     0.204  1.062       0.188  0.999   \n",
       "flan_ul2            0.597  0.901     0.669  1.003       0.570  1.011   \n",
       "gpt35              -0.041  0.629     0.013  0.776      -0.064  0.774   \n",
       "gpt4                0.605  0.719     0.686  0.862       0.592  0.805   \n",
       "tulu2_13b           0.048  0.764     0.004  0.893      -0.073  0.896   \n",
       "tulu2_7b            0.024  0.816     0.128  0.904       0.145  0.911   \n",
       "\n",
       "            white_score        black_score        asian_score         \n",
       "                   mean    std        mean    std        mean    std  \n",
       "model                                                                 \n",
       "flan_t5_xxl       0.291  0.939       0.186  1.269       0.215  1.195  \n",
       "flan_ul2          0.589  0.929       0.379  1.229       0.505  1.211  \n",
       "gpt35             0.050  0.691      -0.133  1.072       0.024  1.034  \n",
       "gpt4              0.706  0.734       0.792  1.123       0.538  1.041  \n",
       "tulu2_13b         0.214  0.816       0.176  1.151      -0.010  1.064  \n",
       "tulu2_7b          0.248  0.781      -0.023  1.095       0.243  1.123  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_error_identity.groupby(['model']).agg([np.mean, np.std]).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base, Distance\n",
    "\n",
    "an indirect statistical test to justify our findings in Fig 2.\n",
    "\n",
    "(We conduct post hoc t-tests with Bonferoni correction to ensure that there are between-group differences in the distances between base predictions and identity labels. In our main findings, we use the gaps in correlation coefficients to illustrate which group the base predictions are closer to.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = p_error_base['model'].unique()\n",
    "results = {'model':[], 'pair':[], 't_stat':[], 'p_value':[]}\n",
    "\n",
    "for i in models:\n",
    "    df = p_error_base[p_error_base['model']==i]\n",
    "    g = stats.ttest_rel(df['man_score'], df['woman_score'], nan_policy=\"omit\")\n",
    "    e1 = stats.ttest_rel(df['white_score'], df['black_score'], nan_policy=\"omit\")\n",
    "    e2 = stats.ttest_rel(df['white_score'], df['asian_score'], nan_policy=\"omit\")\n",
    "    e3 = stats.ttest_rel(df['black_score'], df['asian_score'], nan_policy=\"omit\")\n",
    "    results['model'].extend([i,i,i,i])\n",
    "    results['pair'].extend(['man_woman', 'white_black', 'white_asian', 'black_asian'])\n",
    "    results['t_stat'].extend([g[0], e1[0], e2[0], e3[0]])\n",
    "    results['p_value'].extend([g[1], e1[1], e2[1], e3[1]])\n",
    "\n",
    "p_results_base = pd.DataFrame.from_dict(results, orient=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">t_stat</th>\n",
       "      <th colspan=\"4\" halign=\"left\">p_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pair</th>\n",
       "      <th>black_asian</th>\n",
       "      <th>man_woman</th>\n",
       "      <th>white_asian</th>\n",
       "      <th>white_black</th>\n",
       "      <th>black_asian</th>\n",
       "      <th>man_woman</th>\n",
       "      <th>white_asian</th>\n",
       "      <th>white_black</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>flan_t5_xxl</th>\n",
       "      <td>-4.344</td>\n",
       "      <td>-0.765</td>\n",
       "      <td>-3.828</td>\n",
       "      <td>4.614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flan_ul2</th>\n",
       "      <td>-4.344</td>\n",
       "      <td>-0.760</td>\n",
       "      <td>-3.840</td>\n",
       "      <td>4.614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt35</th>\n",
       "      <td>-4.344</td>\n",
       "      <td>-0.815</td>\n",
       "      <td>-3.828</td>\n",
       "      <td>4.658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4</th>\n",
       "      <td>-4.344</td>\n",
       "      <td>-0.765</td>\n",
       "      <td>-3.828</td>\n",
       "      <td>4.614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tulu2_13b</th>\n",
       "      <td>-4.097</td>\n",
       "      <td>-0.964</td>\n",
       "      <td>-3.849</td>\n",
       "      <td>4.293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tulu2_7b</th>\n",
       "      <td>-4.245</td>\n",
       "      <td>-0.519</td>\n",
       "      <td>-3.740</td>\n",
       "      <td>4.825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 t_stat                                       p_value  \\\n",
       "pair        black_asian man_woman white_asian white_black black_asian   \n",
       "model                                                                   \n",
       "flan_t5_xxl      -4.344    -0.765      -3.828       4.614         0.0   \n",
       "flan_ul2         -4.344    -0.760      -3.840       4.614         0.0   \n",
       "gpt35            -4.344    -0.815      -3.828       4.658         0.0   \n",
       "gpt4             -4.344    -0.765      -3.828       4.614         0.0   \n",
       "tulu2_13b        -4.097    -0.964      -3.849       4.293         0.0   \n",
       "tulu2_7b         -4.245    -0.519      -3.740       4.825         0.0   \n",
       "\n",
       "                                               \n",
       "pair        man_woman white_asian white_black  \n",
       "model                                          \n",
       "flan_t5_xxl     0.444         0.0         0.0  \n",
       "flan_ul2        0.447         0.0         0.0  \n",
       "gpt35           0.415         0.0         0.0  \n",
       "gpt4            0.444         0.0         0.0  \n",
       "tulu2_13b       0.335         0.0         0.0  \n",
       "tulu2_7b        0.604         0.0         0.0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_results_base.pivot(index='model', columns='pair', values=['t_stat', 'p_value']).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distance\n",
    "\n",
    "show that adding identity tokens has influence on the alignment of models' predictions to subgroup labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = p_error_identity['model'].unique()\n",
    "results = {'model':[], 'identity':[], 't_stat':[], 'p_value':[]}\n",
    "\n",
    "for i in models:\n",
    "    df_base = p_error_base[p_error_base['model']==i]\n",
    "    df_identity = p_error_identity[p_error_identity['model']==i]\n",
    "    man = stats.ttest_rel(df_base['man_score'], df_identity['man_score'], nan_policy=\"omit\")\n",
    "    woman = stats.ttest_rel(df_base['woman_score'], df_identity['woman_score'], nan_policy=\"omit\")\n",
    "    white = stats.ttest_rel(df_base['white_score'], df_identity['white_score'], nan_policy=\"omit\")\n",
    "    black = stats.ttest_rel(df_base['black_score'], df_identity['black_score'], nan_policy=\"omit\")\n",
    "    asian = stats.ttest_rel(df_base['asian_score'], df_identity['asian_score'], nan_policy=\"omit\")\n",
    "    results['model'].extend([i,i,i,i,i])\n",
    "    results['identity'].extend(['man', 'woman', 'white', 'black', 'asian'])\n",
    "    results['t_stat'].extend([man[0], woman[0], white[0], black[0], asian[0]])\n",
    "    results['p_value'].extend([man[1], woman[1], white[1], black[1], asian[1]])\n",
    "\n",
    "p_results_identity = pd.DataFrame.from_dict(results, orient=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">t_stat</th>\n",
       "      <th colspan=\"5\" halign=\"left\">p_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>identity</th>\n",
       "      <th>asian</th>\n",
       "      <th>black</th>\n",
       "      <th>man</th>\n",
       "      <th>white</th>\n",
       "      <th>woman</th>\n",
       "      <th>asian</th>\n",
       "      <th>black</th>\n",
       "      <th>man</th>\n",
       "      <th>white</th>\n",
       "      <th>woman</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>flan_t5_xxl</th>\n",
       "      <td>7.566</td>\n",
       "      <td>-7.730</td>\n",
       "      <td>-1.342</td>\n",
       "      <td>-12.974</td>\n",
       "      <td>2.913</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flan_ul2</th>\n",
       "      <td>12.804</td>\n",
       "      <td>9.101</td>\n",
       "      <td>-11.513</td>\n",
       "      <td>1.568</td>\n",
       "      <td>3.387</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt35</th>\n",
       "      <td>2.117</td>\n",
       "      <td>-1.334</td>\n",
       "      <td>-12.440</td>\n",
       "      <td>-12.526</td>\n",
       "      <td>3.550</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4</th>\n",
       "      <td>13.297</td>\n",
       "      <td>-24.788</td>\n",
       "      <td>-15.610</td>\n",
       "      <td>-15.938</td>\n",
       "      <td>1.540</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tulu2_13b</th>\n",
       "      <td>10.572</td>\n",
       "      <td>-17.166</td>\n",
       "      <td>2.844</td>\n",
       "      <td>-20.446</td>\n",
       "      <td>13.265</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tulu2_7b</th>\n",
       "      <td>-6.224</td>\n",
       "      <td>-4.682</td>\n",
       "      <td>-15.074</td>\n",
       "      <td>-23.456</td>\n",
       "      <td>-15.345</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             t_stat                                 p_value                \\\n",
       "identity      asian   black     man   white   woman   asian  black    man   \n",
       "model                                                                       \n",
       "flan_t5_xxl   7.566  -7.730  -1.342 -12.974   2.913   0.000  0.000  0.180   \n",
       "flan_ul2     12.804   9.101 -11.513   1.568   3.387   0.000  0.000  0.000   \n",
       "gpt35         2.117  -1.334 -12.440 -12.526   3.550   0.034  0.182  0.000   \n",
       "gpt4         13.297 -24.788 -15.610 -15.938   1.540   0.000  0.000  0.000   \n",
       "tulu2_13b    10.572 -17.166   2.844 -20.446  13.265   0.000  0.000  0.004   \n",
       "tulu2_7b     -6.224  -4.682 -15.074 -23.456 -15.345   0.000  0.000  0.000   \n",
       "\n",
       "                           \n",
       "identity     white  woman  \n",
       "model                      \n",
       "flan_t5_xxl  0.000  0.004  \n",
       "flan_ul2     0.117  0.001  \n",
       "gpt35        0.000  0.000  \n",
       "gpt4         0.000  0.124  \n",
       "tulu2_13b    0.000  0.000  \n",
       "tulu2_7b     0.000  0.000  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_results_identity.pivot(index='model', columns='identity', values=['t_stat', 'p_value']).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction\n",
    "\n",
    "show that there is significant difference of models' behavior w/o identity tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_pred_error = (polite.loc[:, 'flant5_xxl_base':'gpt4_asian'].reset_index()\n",
    "                .melt(id_vars='index', value_name='pred', var_name='var'))\n",
    "p_pred_error['model'] = p_pred_error['var'].apply(lambda x: re.split(r'_[a-z]+$', x)[0])\n",
    "p_pred_error['identity'] = p_pred_error['var'].apply(lambda x: re.findall(r'[a-z]+$', x)[0])\n",
    "del p_pred_error['var']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = p_pred_error['model'].unique()\n",
    "identities = p_pred_error['identity'].unique()\n",
    "results = {'model':[], 'identity':[], 't_stat':[], 'p_value':[]}\n",
    "\n",
    "for i in models:\n",
    "    df = p_pred_error[p_pred_error['model']==i]\n",
    "    df_base = df[df['identity']=='base']\n",
    "    for j in identities:\n",
    "        if j == \"base\":\n",
    "            continue\n",
    "        df_identity = df[df['identity']==j]\n",
    "        ttest = stats.ttest_rel(df_base['pred'], df_identity['pred'], nan_policy='omit')\n",
    "        results['model'].append(i)\n",
    "        results['identity'].append(j)\n",
    "        results['t_stat'].append(ttest[0])\n",
    "        results['p_value'].append(ttest[1])\n",
    "\n",
    "p_results_pred = pd.DataFrame.from_dict(results, orient=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">t_stat</th>\n",
       "      <th colspan=\"5\" halign=\"left\">p_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>identity</th>\n",
       "      <th>asian</th>\n",
       "      <th>black</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>white</th>\n",
       "      <th>asian</th>\n",
       "      <th>black</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>white</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>flan_ul2</th>\n",
       "      <td>21.871</td>\n",
       "      <td>12.293</td>\n",
       "      <td>3.417</td>\n",
       "      <td>-11.507</td>\n",
       "      <td>1.568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flant5_xxl</th>\n",
       "      <td>12.516</td>\n",
       "      <td>-10.167</td>\n",
       "      <td>3.031</td>\n",
       "      <td>-1.518</td>\n",
       "      <td>-12.974</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt35</th>\n",
       "      <td>4.304</td>\n",
       "      <td>-1.874</td>\n",
       "      <td>3.431</td>\n",
       "      <td>-12.340</td>\n",
       "      <td>-12.557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4</th>\n",
       "      <td>21.239</td>\n",
       "      <td>-32.929</td>\n",
       "      <td>1.582</td>\n",
       "      <td>-15.636</td>\n",
       "      <td>-15.938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tulu2_13b</th>\n",
       "      <td>16.224</td>\n",
       "      <td>-23.318</td>\n",
       "      <td>13.275</td>\n",
       "      <td>3.186</td>\n",
       "      <td>-20.472</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tulu2_7b</th>\n",
       "      <td>-12.027</td>\n",
       "      <td>-5.769</td>\n",
       "      <td>-15.529</td>\n",
       "      <td>-15.187</td>\n",
       "      <td>-23.455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            t_stat                                 p_value                \\\n",
       "identity     asian   black  female    male   white   asian  black female   \n",
       "model                                                                      \n",
       "flan_ul2    21.871  12.293   3.417 -11.507   1.568     0.0  0.000  0.001   \n",
       "flant5_xxl  12.516 -10.167   3.031  -1.518 -12.974     0.0  0.000  0.002   \n",
       "gpt35        4.304  -1.874   3.431 -12.340 -12.557     0.0  0.061  0.001   \n",
       "gpt4        21.239 -32.929   1.582 -15.636 -15.938     0.0  0.000  0.114   \n",
       "tulu2_13b   16.224 -23.318  13.275   3.186 -20.472     0.0  0.000  0.000   \n",
       "tulu2_7b   -12.027  -5.769 -15.529 -15.187 -23.455     0.0  0.000  0.000   \n",
       "\n",
       "                          \n",
       "identity     male  white  \n",
       "model                     \n",
       "flan_ul2    0.000  0.117  \n",
       "flant5_xxl  0.129  0.000  \n",
       "gpt35       0.000  0.000  \n",
       "gpt4        0.000  0.000  \n",
       "tulu2_13b   0.001  0.000  \n",
       "tulu2_7b    0.000  0.000  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_results_pred.pivot(index='model', columns='identity', values=['t_stat', 'p_value']).round(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
