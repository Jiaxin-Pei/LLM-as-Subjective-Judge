### Sociodemographic Prompting is Not Yet an Effective Approach for Simulating Subjective Judgments with LLMs

This is the repository for the paper: Sociodemographic Prompting is Not Yet an Effective Approach for Simulating Subjective Judgments with LLMs

Authors: Huaman Sun, Jiaxin Pei, Minje Choi and David Jurgens

Human judgments are inherently subjective and are actively affected by personal traits such as gender and ethnicity. While Large Language Models (LLMs) are widely used to simulate human responses across diverse contexts, their ability to account for demographic differences in subjective tasks remains uncertain. In this study, leveraging the POPQUORN dataset, we evaluate nine popular LLMs on their ability to understand demographic differences in two subjective judgment tasks: politeness and offensiveness. We find that in zero-shot settings, most models’ predictions for both tasks align more closely with labels from White participants than those from Asian or Black participants, while only a minor gender bias favoring women appears in the politeness task. Furthermore, sociodemo- graphic prompting does not consistently improve and, in some cases, worsens LLMs’ ability to perceive language from specific sub-populations. These findings highlight potential demographic biases in LLMs when performing subjective judgment tasks and un- derscore the limitations of sociodemographic prompting as a strategy to achieve pluralistic alignment.

The paper will be available on Arxiv starting from Nov 16th
